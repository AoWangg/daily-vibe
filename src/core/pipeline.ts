import path from 'node:path'

import {collectClaudeCodeEvents} from '../sources/claude-code.js'
import {collectCodexEvents} from '../sources/codex.js'
import {loadConfig} from '../utils/config.js'
import {ensureDir, writeFile} from '../utils/fs.js'
import {formatDate, getDateRange, getDayRange} from '../utils/time.js'
import {AnalysisResult, AppConfig, SessionEvent, SessionSummary} from '../utils/types.js'
import {createLLMClient, LLMClient} from './llm.js'
import {RedactionEngine} from './redact.js'

export interface AnalyzeOptions {
  date?: Date
  dateRange?: {from: Date; to: Date}
  enableRedaction?: boolean
  outputDir?: string
}

export class AnalysisPipeline {
  private config: AppConfig
  private redactionEngine: RedactionEngine

  constructor(redactionEngine: RedactionEngine, config: AppConfig) {
    this.config = config
    this.redactionEngine = redactionEngine
  }

  static async create(): Promise<AnalysisPipeline> {
    const config = await loadConfig()
    const redactionEngine = new RedactionEngine(config.redact)
    return new AnalysisPipeline(redactionEngine, config)
  }

  async analyzeDateRange(from: Date, to: Date, options: AnalyzeOptions = {}): Promise<AnalysisResult> {
    const {end: rangeEnd, start: rangeStart} = getDateRange(from, to, this.config.timezone)

    // Collect events from all sources
    const [claudeResult, codexResult] = await Promise.all([
      collectClaudeCodeEvents({dayEnd: rangeEnd, dayStart: rangeStart}),
      collectCodexEvents({dayEnd: rangeEnd, dayStart: rangeStart}),
    ])

    // Combine all events
    const allEvents = [...claudeResult.events, ...codexResult.events]
    const allSessions = [...claudeResult.sessions, ...codexResult.sessions]

    // Apply redaction if enabled
    const processedSessions = options.enableRedaction === false ? allSessions : this.redactSessions(allSessions)

    // Split into chunks for analysis
    const chunks = this.splitSessionsIntoChunks(processedSessions)

    // Generate analysis using LLM with chunked approach (å¹¶è¡Œå¤„ç†æ—¥æŠ¥å’ŒçŸ¥è¯†åº“åˆ†æ)
    const llmClient = createLLMClient(this.config.llm)
    const dateRangeStr = `${formatDate(from)} to ${formatDate(to)}`

    const [dailyReport, knowledge] = await Promise.all([
      this.generateChunkedAnalysis(chunks, 'daily', dateRangeStr, llmClient),
      this.generateChunkedAnalysis(chunks, 'knowledge', dateRangeStr, llmClient),
    ])

    const result: AnalysisResult = {
      dailyReport,
      date: dateRangeStr,
      knowledge,
      sessions: processedSessions,
      stats: {
        totalEvents: allEvents.length,
        totalProblems: this.extractProblemSolutions(processedSessions).length,
        totalSessions: allSessions.length,
      },
    }

    // Save to disk if output directory is specified
    if (options.outputDir) {
      await this.saveResults(result, options.outputDir, 'range')
    }

    return result
  }

  async analyzeDay(date: Date, options: AnalyzeOptions = {}): Promise<AnalysisResult> {
    const {end: dayEnd, start: dayStart} = getDayRange(date, this.config.timezone)

    // Collect events from all sources
    const [claudeResult, codexResult] = await Promise.all([
      collectClaudeCodeEvents({dayEnd, dayStart}),
      collectCodexEvents({dayEnd, dayStart}),
    ])

    // Combine all events
    const allEvents = [...claudeResult.events, ...codexResult.events]
    const allSessions = [...claudeResult.sessions, ...codexResult.sessions]

    // Apply redaction if enabled
    const processedSessions = options.enableRedaction === false ? allSessions : this.redactSessions(allSessions)

    // Split into chunks for analysis
    const chunks = this.splitSessionsIntoChunks(processedSessions)

    // Generate analysis using LLM with chunked approach (å¹¶è¡Œå¤„ç†æ—¥æŠ¥å’ŒçŸ¥è¯†åº“åˆ†æ)
    const llmClient = createLLMClient(this.config.llm)
    const dateStr = formatDate(date)

    const [dailyReport, knowledge] = await Promise.all([
      this.generateChunkedAnalysis(chunks, 'daily', dateStr, llmClient),
      this.generateChunkedAnalysis(chunks, 'knowledge', dateStr, llmClient),
    ])

    const result: AnalysisResult = {
      dailyReport,
      date: dateStr,
      knowledge,
      sessions: processedSessions,
      stats: {
        totalEvents: allEvents.length,
        totalProblems: this.extractProblemSolutions(processedSessions).length,
        totalSessions: allSessions.length,
      },
    }

    // Save to disk if output directory is specified
    if (options.outputDir) {
      await this.saveResults(result, options.outputDir)
    }

    return result
  }

  private containsErrorPattern(content: string): boolean {
    const errorPatterns = [
      /error|exception|traceback|npm ERR!/i,
      /TypeError|ValueError|SyntaxError|ReferenceError/i,
      /panic|fatal|abort|crash/i,
      /failed|failure|unsuccessful/i,
      /cannot find|not found|undefined|null/i,
      /permission denied|access denied/i,
      /connection refused|timeout/i,
    ]

    return errorPatterns.some((pattern) => pattern.test(content))
  }

  private createDailyIntegrationPrompt(chunkAnalyses: string[], dateStr: string): string {
    return `è¯·æ•´åˆä»¥ä¸‹å¤šä¸ªæ—¶æ®µçš„å¼€å‘æ—¥æŠ¥åˆ†æï¼Œç”Ÿæˆç»Ÿä¸€çš„æ—¥æŠ¥ï¼š

æ—¥æœŸï¼š${dateStr}

åˆ†æ®µåˆ†æç»“æœï¼š
${chunkAnalyses.map((analysis, index) => `## æ—¶æ®µ ${index + 1}ï¼š\n${analysis}\n`).join('\n---\n\n')}

è¯·å°†è¿™äº›åˆ†æ®µåˆ†ææ•´åˆæˆä¸€ä»½å®Œæ•´çš„å¼€å‘æ—¥æŠ¥ï¼ŒåŒ…æ‹¬ï¼š
1. æ•´ä½“æ¦‚è§ˆï¼ˆåˆå¹¶æ‰€æœ‰æ—¶æ®µçš„ä¸»è¦å·¥ä½œï¼‰
2. å…³é”®äº§å‡ºï¼ˆå»é‡å¹¶åˆ†ç±»æ•´ç†ï¼‰
3. è¿è¡Œæµ‹è¯•ï¼ˆç»Ÿè®¡æˆåŠŸ/å¤±è´¥æƒ…å†µï¼‰
4. å¾…åŠäº‹é¡¹ï¼ˆåˆå¹¶å¹¶ä¼˜å…ˆçº§æ’åºï¼‰

ä¿æŒåŸæœ‰çš„ä¸­æ–‡æ ¼å¼å’ŒMarkdownç»“æ„ã€‚`
  }

  private createKnowledgeIntegrationPrompt(chunkAnalyses: string[], dateStr: string): string {
    return `è¯·æ•´åˆä»¥ä¸‹å¤šä¸ªæ—¶æ®µçš„çŸ¥è¯†åº“åˆ†æï¼Œç”Ÿæˆç»Ÿä¸€çš„çŸ¥è¯†åº“ï¼š

æ—¥æœŸï¼š${dateStr}

åˆ†æ®µåˆ†æç»“æœï¼š
${chunkAnalyses.map((analysis, index) => `## æ—¶æ®µ ${index + 1}ï¼š\n${analysis}\n`).join('\n---\n\n')}

è¯·å°†è¿™äº›åˆ†æ®µåˆ†ææ•´åˆæˆä¸€ä»½å®Œæ•´çš„çŸ¥è¯†åº“ï¼ŒåŒ…æ‹¬ï¼š
1. å»é‡ç›¸ä¼¼é—®é¢˜ï¼Œä¿ç•™æœ€å®Œæ•´çš„è§£å†³æ–¹æ¡ˆ
2. æŒ‰æŠ€æœ¯é¢†åŸŸåˆ†ç±»æ•´ç†ï¼ˆæ„å»º/ç¼–è¯‘ã€å·¥å…·é…ç½®ã€ä¾èµ–ç®¡ç†ç­‰ï¼‰
3. æå–é€šç”¨è§„åˆ™å’Œæœ€ä½³å®è·µ
4. åˆå¹¶ç›¸å…³çš„è¸©å‘æç¤º

ä¿æŒåŸæœ‰çš„ä¸­æ–‡æ ¼å¼å’ŒMarkdownç»“æ„ã€‚`
  }

  private estimateSessionLength(session: SessionSummary): number {
    const headerLength = 200 // session headeråŸºæœ¬ä¿¡æ¯
    const eventsLength = session.events.reduce((total, event) => total + (event.content?.length || 0) + 150, 0) // timestamp + role + formatting
    return headerLength + eventsLength
  }

  private extractProblemSolutions(sessions: SessionSummary[]): Array<{
    context: string;
    events: SessionEvent[];
    problem: string;
    solution: string;
  }> {
    const problems: Array<{
      context: string;
      events: SessionEvent[];
      problem: string;
      solution: string;
    }> = []

    for (const session of sessions) {
      const {events} = session

      for (let i = 0; i < events.length; i++) {
        const event = events[i]

        // Look for error patterns in user messages and tool outputs
        if (
          this.containsErrorPattern(event.content) ||
          (event.toolRuns && event.toolRuns.some((run) => run.error || run.exitCode !== 0))
        ) {
          // Look for subsequent assistant responses that might be solutions
          const solutionEvents = events.slice(i + 1, i + 5).filter((e) => e.role === 'assistant')

          if (solutionEvents.length > 0) {
            problems.push({
              context: session.project || 'unknown',
              events: [event, ...solutionEvents],
              problem: event.content,
              solution: solutionEvents.map((e) => e.content).join('\n'),
            })
          }
        }
      }
    }

    return problems
  }

  private formatSessionsForLLM(sessions: SessionSummary[]): string {
    const MAX_EVENT_CONTENT_LENGTH = 3000 // å•ä¸ªäº‹ä»¶å†…å®¹æœ€å¤§é•¿åº¦

    return sessions
      .map((session) => {
        const {endTime, events, project, sessionId, startTime} = session
        const processedEvents = events
          .map((event) => {
            // é€‚åº¦æˆªæ–­å•ä¸ªäº‹ä»¶å†…å®¹ï¼Œä¿ç•™é‡è¦ä¿¡æ¯
            let {content} = event
            if (content.length > MAX_EVENT_CONTENT_LENGTH) {
              content = content.slice(0, MAX_EVENT_CONTENT_LENGTH) + '... [å†…å®¹è¿‡é•¿å·²æˆªæ–­]'
            }

            let eventStr = `[${event.timestamp.toISOString()}] ${event.role}: ${content}`

            if (event.toolRuns && event.toolRuns.length > 0) {
              const toolSummary = event.toolRuns
                .map(
                  (run) => `${run.tool || run.command}: ${(run.output || run.error || 'executed').slice(0, 300)}`,
                )
                .join('; ')
              eventStr += `\n  Tools: ${toolSummary}`
            }

            return eventStr
          })
          .slice(0, 100) // æ¯ä¸ªä¼šè¯æœ€å¤š100ä¸ªäº‹ä»¶

        return `Session: ${sessionId} (${
          project || 'unknown project'
        })\nTime: ${startTime.toISOString()} - ${endTime.toISOString()}\n${processedEvents.join('\n')}\n---\n`
      })
      .join('\n')
  }

  private async generateChunkedAnalysis(
    chunks: SessionSummary[][],
    analysisType: 'daily' | 'knowledge',
    dateStr: string,
    llmClient: LLMClient,
  ): Promise<string> {
    if (chunks.length === 0) {
      return analysisType === 'daily'
        ? `# å¼€å‘æ—¥æŠ¥ - ${dateStr}\n\n## ğŸ“Š æ¦‚è§ˆ\næ²¡æœ‰æ‰¾åˆ°ç¼–ç¨‹ä¼šè¯è®°å½•ã€‚`
        : `# çŸ¥è¯†åº“ - ${dateStr}\n\n## â„¹ï¸ è¯´æ˜\næ²¡æœ‰æ‰¾åˆ°å¯åˆ†æçš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆã€‚`
    }

    if (chunks.length === 1) {
      // åªæœ‰ä¸€ä¸ªchunkï¼Œç›´æ¥åˆ†æ
      const sessionSummary = this.formatSessionsForLLM(chunks[0])
      return analysisType === 'daily'
        ? llmClient.summarizeDaily(sessionSummary, dateStr)
        : llmClient.extractKnowledge(sessionSummary, dateStr)
    }

    // å¤šä¸ªchunksï¼Œå¹¶è¡Œåˆ†æç„¶åæ•´åˆ
    console.log(`ğŸ”„ å¹¶è¡Œåˆ†æ ${chunks.length} ä¸ªæ•°æ®å—...`)

    // å¹¶è¡Œåˆ†ææ‰€æœ‰chunks
    const chunkAnalysisPromises = chunks.map(async (chunk, index) => {
      const chunkSummary = this.formatSessionsForLLM(chunk)
      const chunkDateStr = `${dateStr} (ç¬¬${index + 1}/${chunks.length}éƒ¨åˆ†)`

      console.log(`   å¼€å§‹åˆ†æç¬¬ ${index + 1}/${chunks.length} å—...`)

      const analysis =
        analysisType === 'daily'
          ? await llmClient.summarizeDaily(chunkSummary, chunkDateStr)
          : await llmClient.extractKnowledge(chunkSummary, chunkDateStr)

      console.log(`   âœ… å®Œæˆç¬¬ ${index + 1}/${chunks.length} å—åˆ†æ`)
      return analysis
    })

    // ç­‰å¾…æ‰€æœ‰åˆ†æå®Œæˆ
    const chunkAnalyses = await Promise.all(chunkAnalysisPromises)

    // æ•´åˆæ‰€æœ‰chunkçš„åˆ†æç»“æœ
    console.log(`ğŸ”— æ•´åˆåˆ†æç»“æœ...`)
    return this.integrateChunkAnalyses(chunkAnalyses, analysisType, dateStr, llmClient)
  }

  private async integrateChunkAnalyses(
    chunkAnalyses: string[],
    analysisType: 'daily' | 'knowledge',
    dateStr: string,
    llmClient: LLMClient,
  ): Promise<string> {
    const integrationPrompt =
      analysisType === 'daily'
        ? this.createDailyIntegrationPrompt(chunkAnalyses, dateStr)
        : this.createKnowledgeIntegrationPrompt(chunkAnalyses, dateStr)

    // ä½¿ç”¨LLMæ•´åˆæ‰€æœ‰åˆ†æç»“æœ
    return analysisType === 'daily'
      ? llmClient.summarizeDaily(integrationPrompt, dateStr)
      : llmClient.extractKnowledge(integrationPrompt, dateStr)
  }

  private redactSessions(sessions: SessionSummary[]): SessionSummary[] {
    return sessions.map((session) => ({
      ...session,
      events: session.events.map((event) => ({
        ...event,
        content: this.redactionEngine.redact(event.content).redacted,
        toolRuns: event.toolRuns?.map((run) => ({
          ...run,
          input: run.input ? this.redactionEngine.redact(run.input).redacted : run.input,
          output: run.output ? this.redactionEngine.redact(run.output).redacted : run.output,
        })),
      })),
    }))
  }

  private async saveResults(result: AnalysisResult, outputDir: string, prefix = ''): Promise<void> {
    const dirName = prefix ? `${prefix}-${result.date}` : result.date.replace(/\s+to\s+/, '_')
    const reportDir = path.join(outputDir, dirName)

    await ensureDir(reportDir)

    // Save daily report
    await writeFile(path.join(reportDir, 'daily.md'), result.dailyReport)

    // Save knowledge extraction
    await writeFile(path.join(reportDir, 'knowledge.md'), result.knowledge)

    // Save raw data as JSON
    await writeFile(path.join(reportDir, 'data.json'), JSON.stringify(result, null, 2))
  }

  private splitSessionsIntoChunks(sessions: SessionSummary[]): SessionSummary[][] {
    const MAX_CHUNK_LENGTH = 80_000 // ä¿å®ˆä¼°è®¡æ¯ä¸ªchunkçš„å­—ç¬¦æ•°é™åˆ¶
    const chunks: SessionSummary[][] = []
    let currentChunk: SessionSummary[] = []
    let currentChunkLength = 0

    for (const session of sessions) {
      // ä¼°ç®—sessionçš„æ–‡æœ¬é•¿åº¦
      const sessionLength = this.estimateSessionLength(session)

      // å¦‚æœå½“å‰chunkåŠ ä¸Šè¿™ä¸ªsessionè¶…è¿‡é™åˆ¶ï¼Œå¼€å§‹æ–°chunk
      if (currentChunkLength + sessionLength > MAX_CHUNK_LENGTH && currentChunk.length > 0) {
        chunks.push(currentChunk)
        currentChunk = [session]
        currentChunkLength = sessionLength
      } else {
        currentChunk.push(session)
        currentChunkLength += sessionLength
      }
    }

    // æ·»åŠ æœ€åä¸€ä¸ªchunk
    if (currentChunk.length > 0) {
      chunks.push(currentChunk)
    }

    return chunks
  }
}
